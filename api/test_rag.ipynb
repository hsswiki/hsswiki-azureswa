{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Test:\n",
    "    pass\n",
    "\n",
    "type(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, ConfigDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ValidateInvitationRequestPayload(invitation_code='a', invitation_code1='', chat_history='')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from enum import Enum\n",
    "from typing import Literal, Optional\n",
    "\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "from pydantic.alias_generators import to_camel\n",
    "\n",
    "\n",
    "class BasePayloadModel(BaseModel):\n",
    "    model_config = ConfigDict(\n",
    "        alias_generator=to_camel,\n",
    "        populate_by_name=True,\n",
    "    )\n",
    "\n",
    "\n",
    "class ModelWithInvitationCode:\n",
    "    invitation_code1: str = ''\n",
    "\n",
    "\n",
    "class ModelWithResponse:\n",
    "    invitation_code: str = ''\n",
    "\n",
    "\n",
    "class ValidateInvitationRequestPayload(ModelWithInvitationCode, ModelWithResponse, BasePayloadModel):\n",
    "    chat_history: str = ''\n",
    "\n",
    "ValidateInvitationRequestPayload(invitation_code='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging as log\n",
    "from enum import Enum\n",
    "\n",
    "from src.utils.pydantic_utils import FrozenBaseSettings\n",
    "\n",
    "\n",
    "class EmbeddingModels:\n",
    "    AZURE_TEXT_EMBEDDING_3_LARGE = \"azure.text-embedding-3-large\"\n",
    "    AZURE_TEXT_EMBEDDING_3_SMALL = \"azure.text-embedding-3-small\"\n",
    "    AZURE_TEXT_EMBEDDING_ADA_002 = \"azure.text-embedding-ada-002\"\n",
    "\n",
    "\n",
    "class CompletionModels:\n",
    "    AZURE_GPT_4O_MINI = \"azure.gpt-4o-mini\"\n",
    "    AZURE_O1 = \"azure.o1\"\n",
    "\n",
    "\n",
    "COMPLETION_MODEL_CONFIG = {\n",
    "    CompletionModels.AZURE_GPT_4O_MINI: {\n",
    "        \"max_input_tokens\": 128000,\n",
    "        \"max_output_tokens\": 16384,\n",
    "        \"temperature\": 0,\n",
    "    },\n",
    "    CompletionModels.AZURE_O1: {\n",
    "        \"max_input_tokens\": 128000,\n",
    "        \"max_output_tokens\": 32768,\n",
    "        \"temperature\": 1,  # Must be 1 for o1. Otherwise will raise error.\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "class VectorStoreType(str, Enum):\n",
    "    AZURE_AI_SEARCH = \"AZURE_AI_SEARCH\"\n",
    "    CHROMA_DB = \"CHROMA_DB\"\n",
    "\n",
    "\n",
    "class Config(FrozenBaseSettings):\n",
    "    vector_input_folder: str = \"./vector_data/input/\"\n",
    "\n",
    "    # TODO\n",
    "    # For testing. `data/` folder is gitignored.\n",
    "    # chromadb_path: str = \"./data/chromadb\"\n",
    "\n",
    "    chunk_size: int = 1000\n",
    "    chunk_overlap: int = 100\n",
    "    llm_max_try_count: int = 3\n",
    "\n",
    "    vector_store_table_name: str = \"wiki\"\n",
    "    # Collection of ChromaDB or Index of Azure AI Search\n",
    "\n",
    "    litellm_api_key: str = \"\"\n",
    "    litellm_api_base: str = \"\"\n",
    "\n",
    "    vector_store_type: VectorStoreType = VectorStoreType.CHROMA_DB\n",
    "\n",
    "    azure_ai_search_endpoint: str = \"\"\n",
    "    azure_ai_search_key: str = \"\"\n",
    "\n",
    "    embedding_model_name: str = EmbeddingModels.AZURE_TEXT_EMBEDDING_3_SMALL\n",
    "    completion_model_name: str = CompletionModels.AZURE_O1\n",
    "    max_input_tokens: int = COMPLETION_MODEL_CONFIG[completion_model_name][\n",
    "        \"max_input_tokens\"\n",
    "    ]\n",
    "    max_output_tokens: int = COMPLETION_MODEL_CONFIG[completion_model_name][\n",
    "        \"max_output_tokens\"\n",
    "    ]\n",
    "    temperature: int = COMPLETION_MODEL_CONFIG[completion_model_name][\n",
    "        \"temperature\"\n",
    "    ]\n",
    "\n",
    "    def _init_adder(self):\n",
    "        log.info(f\"{self.vector_store_type=}\")\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VectorStoreType.CHROMA_DB: 'CHROMA_DB'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.vector_store_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'  assistant: Ask me anything about Shen! To continue our chat, may I have your invitation code please? Typically, it can be found on the resumes Shen sents out ðŸ˜Š\n",
      "\n",
      "  user: 33\n",
      "\n",
      "  assistant: Thank you. How may I assist you with my knowledge of Shen?\n",
      "\n",
      "  user: hi\n",
      "\n",
      "  assistant: hello'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = \"\"\"\n",
    "'  assistant: Ask me anything about Shen! To continue our chat, may I have your invitation code please? Typically, it can be found on the resumes Shen sents out ðŸ˜Š\\n\\n  user: 33\\n\\n  assistant: Thank you. How may I assist you with my knowledge of Shen?\\n\\n  user: hi\\n\\n  assistant: hello'\n",
    "\"\"\"\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.PersistentClient(\"./data/output/chromadb\")\n",
    "collection = chroma_client.get_or_create_collection(name=\"wiki\")\n",
    "if \"wiki\" in chroma_client.list_collections():\n",
    "    chroma_client.delete_collection(name=\"wiki\")\n",
    "\n",
    "collection = chroma_client.get_or_create_collection(name=\"wiki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must provide an embedding function to compute embeddings.https://docs.trychroma.com/guides/embeddings in upsert.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/hsswiki-azureswa/api/.venv/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:90\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/hsswiki-azureswa/api/.venv/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:406\u001b[39m, in \u001b[36mCollectionCommon._validate_and_prepare_upsert_request\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    403\u001b[39m     validate_record_set_for_embedding(\n\u001b[32m    404\u001b[39m         record_set=upsert_records, embeddable_fields={\u001b[33m\"\u001b[39m\u001b[33mdocuments\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m    405\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m     upsert_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupsert_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/hsswiki-azureswa/api/.venv/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:526\u001b[39m, in \u001b[36mCollectionCommon._embed_record_set\u001b[39m\u001b[34m(self, record_set, embeddable_fields)\u001b[39m\n\u001b[32m    525\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[literal-required]\u001b[39;00m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    528\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRecord does not contain any non-None fields that can be embedded.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    529\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmbeddable Fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membeddable_fields\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    530\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecord Fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    531\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/hsswiki-azureswa/api/.venv/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:535\u001b[39m, in \u001b[36mCollectionCommon._embed\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    536\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou must provide an embedding function to compute embeddings.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    537\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.trychroma.com/guides/embeddings\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    538\u001b[39m     )\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embedding_function(\u001b[38;5;28minput\u001b[39m=\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: You must provide an embedding function to compute embeddings.https://docs.trychroma.com/guides/embeddings",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     22\u001b[39m documents = [\n\u001b[32m     23\u001b[39m     document_1,\n\u001b[32m     24\u001b[39m     document_2,\n\u001b[32m     25\u001b[39m ]\n\u001b[32m     26\u001b[39m uuids = [\u001b[38;5;28mstr\u001b[39m(uuid4()) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(documents))]\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43mvector_store\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43muuids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# vector_store.delete(ids=uuids[-1])\u001b[39;00m\n\u001b[32m     31\u001b[39m results = vector_store.similarity_search_by_vector(\n\u001b[32m     32\u001b[39m     embedding=[\u001b[32m1\u001b[39m], k=\u001b[32m1\u001b[39m\n\u001b[32m     33\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/hsswiki-azureswa/api/.venv/lib/python3.11/site-packages/langchain_core/vectorstores/base.py:287\u001b[39m, in \u001b[36mVectorStore.add_documents\u001b[39m\u001b[34m(self, documents, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m     texts = [doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m    286\u001b[39m     metadatas = [doc.metadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    288\u001b[39m msg = (\n\u001b[32m    289\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`add_documents` and `add_texts` has not been implemented \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    290\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    291\u001b[39m )\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/hsswiki-azureswa/api/.venv/lib/python3.11/site-packages/langchain_chroma/vectorstores.py:570\u001b[39m, in \u001b[36mChroma.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    568\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e.args[\u001b[32m0\u001b[39m] + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + msg)\n\u001b[32m    569\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m empty_ids:\n\u001b[32m    572\u001b[39m     texts_without_metadatas = [texts[j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m empty_ids]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/hsswiki-azureswa/api/.venv/lib/python3.11/site-packages/langchain_chroma/vectorstores.py:556\u001b[39m, in \u001b[36mChroma.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    554\u001b[39m ids_with_metadata = [ids[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m non_empty_ids]\n\u001b[32m    555\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    558\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    559\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids_with_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    563\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mExpected metadata value to be\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/hsswiki-azureswa/api/.venv/lib/python3.11/site-packages/chromadb/api/models/Collection.py:335\u001b[39m, in \u001b[36mCollection.upsert\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupsert\u001b[39m(\n\u001b[32m    311\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    312\u001b[39m     ids: OneOrMany[ID],\n\u001b[32m   (...)\u001b[39m\u001b[32m    322\u001b[39m     uris: Optional[OneOrMany[URI]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    323\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    324\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001b[39;00m\n\u001b[32m    325\u001b[39m \n\u001b[32m    326\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    333\u001b[39m \u001b[33;03m        None\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     upsert_request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_and_prepare_upsert_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mself\u001b[39m._client._upsert(\n\u001b[32m    345\u001b[39m         collection_id=\u001b[38;5;28mself\u001b[39m.id,\n\u001b[32m    346\u001b[39m         ids=upsert_request[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    352\u001b[39m         database=\u001b[38;5;28mself\u001b[39m.database,\n\u001b[32m    353\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/hsswiki-azureswa/api/.venv/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:93\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     92\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(msg).with_traceback(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/hsswiki-azureswa/api/.venv/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:90\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, *args: Any, **kwargs: Any) -> T:\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     92\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/hsswiki-azureswa/api/.venv/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:406\u001b[39m, in \u001b[36mCollectionCommon._validate_and_prepare_upsert_request\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m upsert_records[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    403\u001b[39m     validate_record_set_for_embedding(\n\u001b[32m    404\u001b[39m         record_set=upsert_records, embeddable_fields={\u001b[33m\"\u001b[39m\u001b[33mdocuments\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m    405\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m     upsert_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupsert_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    408\u001b[39m     upsert_embeddings = upsert_records[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/hsswiki-azureswa/api/.venv/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:526\u001b[39m, in \u001b[36mCollectionCommon._embed_record_set\u001b[39m\u001b[34m(self, record_set, embeddable_fields)\u001b[39m\n\u001b[32m    522\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embed(\n\u001b[32m    523\u001b[39m                 \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28mself\u001b[39m._data_loader(uris=cast(URIs, record_set[field]))  \u001b[38;5;66;03m# type: ignore[literal-required]\u001b[39;00m\n\u001b[32m    524\u001b[39m             )\n\u001b[32m    525\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[literal-required]\u001b[39;00m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    528\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRecord does not contain any non-None fields that can be embedded.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    529\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmbeddable Fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membeddable_fields\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    530\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecord Fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    531\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/hsswiki-azureswa/api/.venv/lib/python3.11/site-packages/chromadb/api/models/CollectionCommon.py:535\u001b[39m, in \u001b[36mCollectionCommon._embed\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_embed\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Any) -> Embeddings:\n\u001b[32m    534\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    536\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou must provide an embedding function to compute embeddings.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    537\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.trychroma.com/guides/embeddings\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    538\u001b[39m         )\n\u001b[32m    539\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embedding_function(\u001b[38;5;28minput\u001b[39m=\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: You must provide an embedding function to compute embeddings.https://docs.trychroma.com/guides/embeddings in upsert."
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "vector_store = Chroma(\n",
    "    # Doc: https://python.langchain.com/docs/integrations/vectorstores/chroma/\n",
    "    collection_name=\"example_collection\",\n",
    "    persist_directory=\"./data/output/chromadb\",\n",
    ")\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=1,\n",
    ")\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=2,\n",
    ")\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "]\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "# vector_store.add_documents(documents=documents, ids=uuids, embeddings=)\n",
    "vector_store.add_embeddings(zip(texts, embeddings), metadatas)\n",
    "\n",
    "# vector_store.delete(ids=uuids[-1])\n",
    "\n",
    "results = vector_store.similarity_search_by_vector(\n",
    "    embedding=[1], k=1\n",
    ")\n",
    "for doc in results:\n",
    "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embedding with SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Initialize the embedding model\n",
    "local_embedding_model = SentenceTransformer(\n",
    "    'all-MiniLM-L6-v2')  # Lightweight model\n",
    "\n",
    "\n",
    "def embed_documents_locally(documents: list[Document]) -> list[list[float]]:\n",
    "    \"\"\"\n",
    "    Embeds a list of LangChain Document objects using a local embedding model.\n",
    "\n",
    "    Args:\n",
    "        documents (list[Document]): List of LangChain Document objects.\n",
    "\n",
    "    Returns:\n",
    "        list[list[float]]: List of embeddings (vectors) for each document.\n",
    "    \"\"\"\n",
    "    # Extract text content from each Document\n",
    "    texts = [doc.page_content for doc in documents]\n",
    "\n",
    "    # Generate embeddings\n",
    "    embeddings = local_embedding_model.encode(\n",
    "        texts, convert_to_numpy=True).tolist()\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# Example usage\n",
    "documents = [\n",
    "    Document(page_content=\"This is the first document.\"),\n",
    "    Document(page_content=\"This is the second document.\"),\n",
    "]\n",
    "embeddings = embed_documents_locally(documents)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.schema import Document\n",
    "# Initialize the embedding model\n",
    "local_embedding_model = SentenceTransformer(\n",
    "    'all-MiniLM-L6-v2')  # Example model, replace as needed\n",
    "\n",
    "\n",
    "def embed_documents_locally(documents: list[Document]) -> list[list[float]]:\n",
    "    \"\"\"\n",
    "    Embeds a list of LangChain Document objects using a local embedding model.\n",
    "\n",
    "    Args:\n",
    "        documents (list[Document]): List of LangChain Document objects.\n",
    "\n",
    "    Returns:\n",
    "        list[list[float]]: List of embeddings (vectors) for each document.\n",
    "    \"\"\"\n",
    "    # Extract text content from each Document\n",
    "    texts = [doc.page_content for doc in documents]\n",
    "\n",
    "    # Generate embeddings\n",
    "    embeddings = local_embedding_model.encode(\n",
    "        texts, convert_to_numpy=True).tolist()\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "# Example usage\n",
    "# documents = [Document(page_content=\"Example text 1\"), Document(page_content=\"Example text 2\")]\n",
    "# embeddings = embed_documents_locally(documents)\n",
    "# print(embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
